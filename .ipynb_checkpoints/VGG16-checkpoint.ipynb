{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<input data 경로 확인>\n",
        "- 구글드라이브에 저장한 이미지 데이터를 사용하기 위해 구글드라이브 마운트"
      ],
      "metadata": {
        "id": "dnP4L5zq_5fX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhD8nnj-3vuj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNLCssTVrgLZ"
      },
      "source": [
        "<image data set 추가하는 과정> (**실행할 필요 X** > 다운받아서 DATA SET 폴더에 이미 합침)\n",
        "- helmet, hat 사진 각 500장식 다운"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiN5LCmCZ88V"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/EscVM/OIDv4_ToolKit.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpWEBqEoaUQx"
      },
      "outputs": [],
      "source": [
        "!pip3 install -r /content/OIDv4_ToolKit/requirements.txt --no-deps \n",
        "#에러 안뜨면 --no -deps 없애도 무방"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ekGaO5-ex0v"
      },
      "outputs": [],
      "source": [
        "!python /content/OIDv4_ToolKit/main.py downloader --classes Hat --type_csv test --limit 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjMH0K0TdNT8"
      },
      "outputs": [],
      "source": [
        "!python /content/OIDv4_ToolKit/main.py downloader --classes Helmet --type_csv test --limit 500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi8y1HkL1e6w"
      },
      "source": [
        "<데이터 Split>\n",
        "- 모은 데이터셋을 train, valid, test 데이터로 0.8/0.1/0.1 비율로 나눔"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#개인별 경로 설정 필요!\n",
        "data_path = \"/content/drive/MyDrive/프로젝트/DATA SET\"\n",
        "destination_path = \"/content/drive/MyDrive/프로젝트/image data\""
      ],
      "metadata": {
        "id": "C4m8DbShFvTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMURR5YpfyXu"
      },
      "outputs": [],
      "source": [
        "pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzaQaKnlftaH"
      },
      "outputs": [],
      "source": [
        "import splitfolders\n",
        "folder_location = data_path\n",
        "categories = [\"helmet\", \"no helmet\"]\n",
        "\n",
        "for index, categories in enumerate(categories):\n",
        "  splitfolders.ratio(folder_location, output=destination_path, seed=77, ratio=(0, 0.8, 0.2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<이미지 파일명 변경> (실행할 필요X, 필수적X > 이미 파일명 전부 변경하여 DATA SET에 반영함)\n",
        "- 데이터 수 확인 및 데이터 상황 점검을 용이하게 하기 위해 이미지마다 번호 부여"
      ],
      "metadata": {
        "id": "kRa0sFinAUKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path1 = \"/content/drive/MyDrive/프로젝트/image data/test/HELMET\"\n",
        "path2 = \"/content/drive/MyDrive/프로젝트/image data/test/NO HELMET\"\n",
        "path3 = \"/content/drive/MyDrive/프로젝트/image data/train/HELMET\"\n",
        "path4 = \"/content/drive/MyDrive/프로젝트/image data/train/NO HELMET\"\n",
        "path5 = \"/content/drive/MyDrive/프로젝트/image data/val/HELMET\"\n",
        "path6 = \"/content/drive/MyDrive/프로젝트/image data/val/NO HELMET\""
      ],
      "metadata": {
        "id": "bEwbrVfAIv_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x5LPGfihRI4"
      },
      "outputs": [],
      "source": [
        "#이미지파일 이름 일괄변경\n",
        "import os\n",
        "folder_path=path6 #path1~path6까지 전부 한번씩 실행해야함\n",
        "folderlist=os.listdir(folder_path)\n",
        "\n",
        "i=1\n",
        "\n",
        "for name in folderlist:\n",
        "    src = os.path.join(folder_path, name)\n",
        "    dst = 'validNoHelmet' + str(i) + '.jpg' #디렉토리에 따라 test/train/valid + Helmet/NoHelmet으로 바꾸기\n",
        "    dst = os.path.join(folder_path, dst)\n",
        "    os.rename(src,dst)\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<이미지 전처리>\n",
        "- ImageDateGenerator를 사용하여 train data를 여러 방법으로 증강시킴\n",
        "- flow_from_directory를 사용하여 train, valid, test data를 224*224 사이즈로 resize하고 numpy array iterator로 바꿈"
      ],
      "metadata": {
        "id": "MW3VIVaiBWpL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOSNb76X3bPa"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#개인에 맞게 path 설정 필요!\n",
        "train_path = '/content/drive/MyDrive/프로젝트/image data/train'\n",
        "val_path = '/content/drive/MyDrive/프로젝트/image data/val'\n",
        "test_path = '/content/drive/MyDrive/프로젝트/image data/test'"
      ],
      "metadata": {
        "id": "ZUxpOjKYFMCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bV5lD7ke2_sl"
      },
      "outputs": [],
      "source": [
        "#Creating generator for Training DataSet\n",
        "train_datagen = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input,\n",
        "        shear_range=0.1, #이미지 기울기\n",
        "        zoom_range=0.1, #이미지 일부 확대\n",
        "        horizontal_flip=True, #이미지 가로 뒤집기\n",
        "        rescale=1/255., #값을 0과 1사이로 변경\n",
        "        rotation_range = 45.0, #이미지 회전값\n",
        "        width_shift_range=0.4, #좌우이동\n",
        "        fill_mode='nearest' #input 경계의 바깥공간을 채우는 방법\n",
        "        )\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        target_size=(224, 224), #이미지 사이즈\n",
        "        batch_size=64, #배치 사이즈\n",
        "        class_mode='categorical' #Y값 변화방법\n",
        "        )\n",
        "\n",
        "#Creating generator for Validation DataSet\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, rescale=1/255.)\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "        val_path,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "#Creating generator for Test DataSet\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,rescale=1/255.)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_path,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<1-1. keras.VGG16 활용하기>\n",
        "- 2번 코드와 분리하여 실행할 것"
      ],
      "metadata": {
        "id": "qn7A6dj_EXBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiate a base model with pre-trained weigts.\n",
        "base_model=keras.applications.VGG16(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\", #pretrained data\n",
        "    input_shape=(224,224,3))"
      ],
      "metadata": {
        "id": "19VUAi39EHGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e695ea26-63bd-4ac5-9cc7-500b441938bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#freeze the base model\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "gguNyRkKEPKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create new model on top\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Flatten,Dropout\n",
        "model=Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096,activation='relu',kernel_initializer='he_normal'))\n",
        "model.add(Dropout(0.35))\n",
        "model.add(Dense(4096,activation='relu',kernel_initializer='he_normal'))\n",
        "model.add(Dropout(0.35))\n",
        "model.add(Dense(2,activation='softmax',kernel_initializer='glorot_normal'))"
      ],
      "metadata": {
        "id": "iJe9V-EgERB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#earlystopping 없는 버전\n",
        "#Train the model on new data.\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "history=model.fit(train_generator,epochs=50,validation_data=val_generator,workers=10,use_multiprocessing=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoOYDUrIMrZU",
        "outputId": "758474e1-fa88-4069-a950-9e49633f1320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "15/15 [==============================] - 648s 43s/step - loss: 0.6542 - accuracy: 0.7844 - val_loss: 0.4745 - val_accuracy: 0.7719\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4913 - accuracy: 0.7941 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#earlystopping 있는 버전\n",
        "#Train the model on new data.\n",
        "callback = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss=keras.losses.BinaryCrossentropy(),metrics=['accuracy'])\n",
        "history=model.fit(train_generator,epochs=50,validation_data=val_generator,workers=10,use_multiprocessing=True, callbacks= [callback])"
      ],
      "metadata": {
        "id": "CDcrw9uoEU2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c3323e-cda8-4f02-c285-3a8a4893b65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "15/15 [==============================] - 642s 41s/step - loss: 0.4859 - accuracy: 0.7714 - val_loss: 0.4106 - val_accuracy: 0.8246\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 629s 41s/step - loss: 0.4663 - accuracy: 0.7876 - val_loss: 0.4065 - val_accuracy: 0.8421\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 637s 43s/step - loss: 0.4799 - accuracy: 0.8007 - val_loss: 0.4116 - val_accuracy: 0.8246\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 633s 41s/step - loss: 0.4189 - accuracy: 0.8028 - val_loss: 0.4580 - val_accuracy: 0.8070\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 627s 40s/step - loss: 0.3907 - accuracy: 0.8267 - val_loss: 0.4108 - val_accuracy: 0.8246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델의 레이어 구성 확인\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "NlDSldZoESzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<1-2. 결과 시각화>"
      ],
      "metadata": {
        "id": "27a3R3lTEqWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Some visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "#Loss\n",
        "plt.plot(history.history['loss'],label='loss')\n",
        "plt.plot(history.history['val_loss'],label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "#Accuracy\n",
        "plt.plot(history.history['accuracy'],label='acc')\n",
        "plt.plot(history.history['val_accuracy'],label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G_UlfWrEEpJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTWhHK7t28p_"
      },
      "source": [
        "<2. VGG16 layer 쌓아 구현>\n",
        "- 1번 코드 실행한 경우 실행하지 말아야 함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpJCUIwi08ni"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import Activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4Go-2jH2pXR"
      },
      "outputs": [],
      "source": [
        "base_model = Sequential()\n",
        "base_model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "base_model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "base_model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "base_model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "base_model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "base_model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "base_model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "base_model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "base_model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "base_model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "base_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "base_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "base_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "base_model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "base_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "base_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "base_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "base_model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMFEHU_J47rY"
      },
      "outputs": [],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFKTIQLqpXk1"
      },
      "outputs": [],
      "source": [
        "model=Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=4096,activation=\"relu\", kernel_initializer='he_normal'))\n",
        "model.add(Dropout(0.35)) #overfitting 방지\n",
        "model.add(Dense(units=4096,activation=\"relu\", kernel_initializer='he_normal'))\n",
        "model.add(Dropout(0.35))\n",
        "model.add(Dense(units=2, activation=\"softmax\",kernel_initializer='glorot_normal'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omBOaNhLp9cE"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xl3A67bOtiZf"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "from keras import losses\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxlhlwMJ5L8g"
      },
      "outputs": [],
      "source": [
        "#Train the model on new data.\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath = \"vgg16_1.h5\", \n",
        "    monitor='loss', \n",
        "    verbose=0, \n",
        "    save_best_only=True, \n",
        "    save_weights_only=False, \n",
        "    mode='auto', \n",
        "    save_period=1)\n",
        "early = EarlyStopping(\n",
        "    monitor='loss', \n",
        "    min_delta=0, \n",
        "    patience=10, \n",
        "    verbose=1, \n",
        "    mode='auto')\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss=keras.losses.BinaryCrossentropy(),metrics=['accuracy'])\n",
        "history=model.fit(\n",
        "    x=train_generator,\n",
        "    y=None,\n",
        "    batch_size=None,\n",
        "    epochs=20,\n",
        "    verbose='auto',\n",
        "    callbacks=[early, checkpoint],\n",
        "    validation_split=0.0,\n",
        "    validation_data=val_generator,\n",
        "    shuffle=True,\n",
        "    class_weight=None,\n",
        "    sample_weight=None,\n",
        "    initial_epoch=0,\n",
        "    steps_per_epoch=None,\n",
        "    validation_steps=None,\n",
        "    validation_batch_size=None,\n",
        "    validation_freq=1,\n",
        "    max_queue_size=10,\n",
        "    workers=10,\n",
        "    use_multiprocessing=True,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}