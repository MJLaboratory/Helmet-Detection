{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnP4L5zq_5fX"
   },
   "source": [
    "<input data 경로 확인>\n",
    "- 구글드라이브에 저장한 이미지 데이터를 사용하기 위해 구글드라이브 마운트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhD8nnj-3vuj"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNLCssTVrgLZ"
   },
   "source": [
    "<image data set 추가하는 과정> (**실행할 필요 X** > 다운받아서 DATA SET 폴더에 이미 합침)\n",
    "- helmet, hat 사진 각 500장식 다운"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hiN5LCmCZ88V"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/EscVM/OIDv4_ToolKit.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpWEBqEoaUQx"
   },
   "outputs": [],
   "source": [
    "!pip3 install -r /content/OIDv4_ToolKit/requirements.txt --no-deps \n",
    "#에러 안뜨면 --no -deps 없애도 무방"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ekGaO5-ex0v"
   },
   "outputs": [],
   "source": [
    "!python /content/OIDv4_ToolKit/main.py downloader --classes Hat --type_csv test --limit 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cjMH0K0TdNT8"
   },
   "outputs": [],
   "source": [
    "!python /content/OIDv4_ToolKit/main.py downloader --classes Helmet --type_csv test --limit 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xi8y1HkL1e6w"
   },
   "source": [
    "<데이터 Split>\n",
    "- 모은 데이터셋을 train, valid, test 데이터로 0.8/0.1/0.1 비율로 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "C4m8DbShFvTI"
   },
   "outputs": [],
   "source": [
    "#개인별 경로 설정 필요!\n",
    "data_path = 'dataset/yolo_cropped_image_data/croped'\n",
    "destination_path = 'dataset/yolo_cropped_image_data_splitted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KMURR5YpfyXu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting split-folders\n",
      "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
      "Installing collected packages: split-folders\n",
      "Successfully installed split-folders-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kzaQaKnlftaH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 1258 files [00:22, 56.14 files/s]\n",
      "Copying files: 1258 files [00:04, 271.09 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "folder_location = data_path\n",
    "categories = [\"helmet\", \"no helmet\"]\n",
    "\n",
    "for index, categories in enumerate(categories):\n",
    "  splitfolders.ratio(folder_location, output=destination_path, seed=77, ratio=(0.8, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRa0sFinAUKK"
   },
   "source": [
    "<이미지 파일명 변경> (실행할 필요X, 필수적X > 이미 파일명 전부 변경하여 DATA SET에 반영함)\n",
    "- 데이터 수 확인 및 데이터 상황 점검을 용이하게 하기 위해 이미지마다 번호 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEwbrVfAIv_w"
   },
   "outputs": [],
   "source": [
    "path1 = \"/content/drive/MyDrive/프로젝트/image data/test/HELMET\"\n",
    "path2 = \"/content/drive/MyDrive/프로젝트/image data/test/NO HELMET\"\n",
    "path3 = \"/content/drive/MyDrive/프로젝트/image data/train/HELMET\"\n",
    "path4 = \"/content/drive/MyDrive/프로젝트/image data/train/NO HELMET\"\n",
    "path5 = \"/content/drive/MyDrive/프로젝트/image data/val/HELMET\"\n",
    "path6 = \"/content/drive/MyDrive/프로젝트/image data/val/NO HELMET\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8x5LPGfihRI4"
   },
   "outputs": [],
   "source": [
    "#이미지파일 이름 일괄변경\n",
    "import os\n",
    "folder_path=path6 #path1~path6까지 전부 한번씩 실행해야함\n",
    "folderlist=os.listdir(folder_path)\n",
    "\n",
    "i=1\n",
    "\n",
    "for name in folderlist:\n",
    "    src = os.path.join(folder_path, name)\n",
    "    dst = 'validNoHelmet' + str(i) + '.jpg' #디렉토리에 따라 test/train/valid + Helmet/NoHelmet으로 바꾸기\n",
    "    dst = os.path.join(folder_path, dst)\n",
    "    os.rename(src,dst)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MW3VIVaiBWpL"
   },
   "source": [
    "<이미지 전처리>\n",
    "- ImageDateGenerator를 사용하여 train data를 여러 방법으로 증강시킴\n",
    "- flow_from_directory를 사용하여 train, valid, test data를 224*224 사이즈로 resize하고 numpy array iterator로 바꿈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vOSNb76X3bPa"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZUxpOjKYFMCu"
   },
   "outputs": [],
   "source": [
    "#개인에 맞게 path 설정 필요!\n",
    "train_path = 'dataset/yolo_cropped_image_data_splitted/train'\n",
    "val_path = 'dataset/yolo_cropped_image_data_splitted/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bV5lD7ke2_sl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1005 images belonging to 3 classes.\n",
      "Found 253 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#Creating generator for Training DataSet\n",
    "train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        shear_range=0.1, #이미지 기울기\n",
    "        zoom_range=0.1, #이미지 일부 확대\n",
    "        horizontal_flip=True, #이미지 가로 뒤집기\n",
    "        rescale=1/255., #값을 0과 1사이로 변경\n",
    "        rotation_range = 45.0, #이미지 회전값\n",
    "        width_shift_range=0.4, #좌우이동\n",
    "        fill_mode='nearest' #input 경계의 바깥공간을 채우는 방법\n",
    "        )\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(224, 224), #이미지 사이즈\n",
    "        batch_size=64, #배치 사이즈\n",
    "        class_mode='categorical' #Y값 변화방법\n",
    "        )\n",
    "\n",
    "#Creating generator for Validation DataSet\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, rescale=1/255.)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qn7A6dj_EXBW"
   },
   "source": [
    "<1-1. keras.VGG16 활용하기>\n",
    "- 2번 코드와 분리하여 실행할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19VUAi39EHGd",
    "outputId": "e695ea26-63bd-4ac5-9cc7-500b441938bb"
   },
   "outputs": [],
   "source": [
    "#instantiate a base model with pre-trained weigts.\n",
    "base_model=keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\", #pretrained data\n",
    "    input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gguNyRkKEPKQ"
   },
   "outputs": [],
   "source": [
    "#freeze the base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "iJe9V-EgERB_"
   },
   "outputs": [],
   "source": [
    "#Create new model on top\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Dropout\n",
    "model=Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096,activation='relu',kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(4096,activation='relu',kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(2,activation='softmax',kernel_initializer='glorot_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BoOYDUrIMrZU",
    "outputId": "758474e1-fa88-4069-a950-9e49633f1320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-38:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 759, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 736, in pool_fn\n",
      "    pool = get_pool_class(True)(\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\multiprocessing\\context.py\", line 119, in Pool\n",
      "    return Pool(processes, initializer, initargs, maxtasksperchild,\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\multiprocessing\\pool.py\", line 212, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\multiprocessing\\pool.py\", line 303, in _repopulate_pool\n",
      "    return self._repopulate_pool_static(self._ctx, self.Process,\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\multiprocessing\\pool.py\", line 326, in _repopulate_pool_static\n",
      "    w.start()\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\multiprocessing\\context.py\", line 327, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\multiprocessing\\popen_spawn_win32.py\", line 93, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "TypeError: cannot pickle '_thread.lock' object\n"
     ]
    }
   ],
   "source": [
    "#earlystopping 없는 버전\n",
    "#Train the model on new data.\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "history=model.fit(train_generator,epochs=50,validation_data=val_generator,workers=10,use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CDcrw9uoEU2e",
    "outputId": "d9c3323e-cda8-4f02-c285-3a8a4893b65c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 759, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 736, in pool_fn\n",
      "    pool = get_pool_class(True)(\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\multiprocessing\\context.py\", line 119, in Pool\n",
      "    return Pool(processes, initializer, initargs, maxtasksperchild,\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\multiprocessing\\pool.py\", line 212, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\multiprocessing\\pool.py\", line 303, in _repopulate_pool\n",
      "    return self._repopulate_pool_static(self._ctx, self.Process,\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\multiprocessing\\pool.py\", line 326, in _repopulate_pool_static\n",
      "    w.start()\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\multiprocessing\\context.py\", line 327, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\multiprocessing\\popen_spawn_win32.py\", line 93, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"C:\\Users\\mjluc\\anaconda3\\envs\\pyln\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "TypeError: cannot pickle '_thread.lock' object\n"
     ]
    }
   ],
   "source": [
    "#earlystopping 있는 버전\n",
    "#Train the model on new data.\n",
    "callback = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss=keras.losses.BinaryCrossentropy(),metrics=['accuracy'])\n",
    "history=model.fit(train_generator,epochs=50,validation_data=val_generator,workers=10,use_multiprocessing=True, callbacks= [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlDSldZoESzV"
   },
   "outputs": [],
   "source": [
    "#모델의 레이어 구성 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27a3R3lTEqWt"
   },
   "source": [
    "<1-2. 결과 시각화>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_UlfWrEEpJy"
   },
   "outputs": [],
   "source": [
    "#Some visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "#Loss\n",
    "plt.plot(history.history['loss'],label='loss')\n",
    "plt.plot(history.history['val_loss'],label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#Accuracy\n",
    "plt.plot(history.history['accuracy'],label='acc')\n",
    "plt.plot(history.history['val_accuracy'],label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTWhHK7t28p_"
   },
   "source": [
    "<2. VGG16 layer 쌓아 구현>\n",
    "- 1번 코드 실행한 경우 실행하지 말아야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tpJCUIwi08ni"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4Go-2jH2pXR"
   },
   "outputs": [],
   "source": [
    "base_model = Sequential()\n",
    "base_model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "base_model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "base_model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "base_model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "base_model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "base_model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "base_model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "base_model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "base_model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "base_model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "base_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "base_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "base_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "base_model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "base_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "base_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "base_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "base_model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMFEHU_J47rY"
   },
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zFKTIQLqpXk1"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\", kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.35)) #overfitting 방지\n",
    "model.add(Dense(units=4096,activation=\"relu\", kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(units=2, activation=\"softmax\",kernel_initializer='glorot_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omBOaNhLp9cE"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xl3A67bOtiZf"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxlhlwMJ5L8g"
   },
   "outputs": [],
   "source": [
    "#Train the model on new data.\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath = \"vgg16_1.h5\", \n",
    "    monitor='loss', \n",
    "    verbose=0, \n",
    "    save_best_only=True, \n",
    "    save_weights_only=False, \n",
    "    mode='auto', \n",
    "    save_period=1)\n",
    "early = EarlyStopping(\n",
    "    monitor='loss', \n",
    "    min_delta=0, \n",
    "    patience=10, \n",
    "    verbose=1, \n",
    "    mode='auto')\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-4),loss=keras.losses.BinaryCrossentropy(),metrics=['accuracy'])\n",
    "history=model.fit(\n",
    "    x=train_generator,\n",
    "    y=None,\n",
    "    batch_size=None,\n",
    "    epochs=20,\n",
    "    verbose='auto',\n",
    "    callbacks=[early, checkpoint],\n",
    "    validation_split=0.0,\n",
    "    validation_data=val_generator,\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=None,\n",
    "    validation_steps=None,\n",
    "    validation_batch_size=None,\n",
    "    validation_freq=1,\n",
    "    max_queue_size=10,\n",
    "    workers=10,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
